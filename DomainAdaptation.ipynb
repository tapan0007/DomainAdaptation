{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1e1d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "import argparse\n",
    "import shutil\n",
    "import os.path as osp\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter\n",
    "from collections import OrderedDict\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from torch import optim,nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms as T,models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.utils import make_grid\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "import itertools\n",
    "\n",
    "\n",
    "from real_world.common.utils.data import ForeverDataIterator\n",
    "from real_world.common.utils.metric import accuracy\n",
    "from real_world.common.utils.meter import AverageMeter, ProgressMeter\n",
    "from real_world.common.utils.logger import CompleteLogger\n",
    "from real_world.common.utils.analysis import collect_feature, tsne, a_distance\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10c5a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = T.Compose([\n",
    "    T.RandomRotation((-20,+20)),\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "data_nih = pd.read_csv('../../data/ChestXRay/NIH/sample/sample_labels.csv')\n",
    "data_nih_no = data_nih[((data_nih['Finding Labels'].str.contains(\"No Finding\")))].sample(n = 500)\n",
    "data_nih_yes = data_nih[((data_nih['Finding Labels'].str.contains(\"Pneumonia\")))]\n",
    "data_nih = pd.concat([data_nih_yes, data_nih_no])\n",
    "data_nih['Pneumonia'] = data_nih['Finding Labels'].apply(lambda x: 1 if 'Pneumonia' in x else 0)\n",
    "data_nih = data_nih.drop(list(data_nih.iloc[:,1:11].columns.values),axis = 1)\n",
    "data_nih = data_nih.reset_index()\n",
    "data_nih = data_nih.drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc92250",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Guangzhou_Dataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.data = os.listdir(img_dir)\n",
    "        self.img_dir = img_dir \n",
    "        self.transform = transform\n",
    "        self.dom = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_file = self.img_dir + self.data[idx]\n",
    "        img = Image.open(img_file).convert('RGB')\n",
    "        if \"person\" in self.data[idx]:\n",
    "            label = np.array([1])\n",
    "        else:\n",
    "            label = np.array([0])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img,label,np.array([self.dom])\n",
    "\n",
    "\n",
    "class NIH_Dataset(Dataset):\n",
    "    def __init__(self, data, img_dir, transform=None):\n",
    "        self.data = data\n",
    "        self.img_dir = img_dir \n",
    "        self.transform = transform \n",
    "        self.dom = 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_file = self.img_dir + self.data.iloc[:,0][idx]\n",
    "        img = Image.open(img_file).convert('RGB')\n",
    "        label = np.array(self.data.iloc[:,1:].iloc[idx])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img,label, np.array([self.dom])\n",
    "    \n",
    "def deprocess(img):\n",
    "    img = img.permute(1,2,0)\n",
    "    img = img * torch.Tensor([0.229, 0.224, 0.225]) + torch.Tensor([0.485, 0.456, 0.406])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7f09e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DIR = '../../data/ChestXRay/chest_xray/train/'\n",
    "TARGET_DIR = '../../data/ChestXRay/NIH/sample/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33ba224",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainds_g = Guangzhou_Dataset(img_dir = SOURCE_DIR,transform = data_transform)\n",
    "\n",
    "trainds_nih = NIH_Dataset(data_nih,\n",
    "                      img_dir = TARGET_DIR ,\n",
    "                      transform = data_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48d581bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train_loader = DataLoader(trainds_g,\n",
    "                         batch_size = 16,\n",
    "                         shuffle = True)\n",
    "\n",
    "target_train_loader = DataLoader(trainds_nih,\n",
    "                         batch_size = 16,\n",
    "                         shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "240d54b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, n_layers=1, hidden_dim=256):\n",
    "        super(MLP, self).__init__()\n",
    "        model = []\n",
    "        model += [nn.Linear(input_dim, hidden_dim), nn.ReLU()]\n",
    "        for _ in range(n_layers):\n",
    "            model += [nn.Linear(hidden_dim, hidden_dim), nn.ReLU()]\n",
    "        model += [nn.Linear(hidden_dim, output_dim)]\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class iVAE(nn.Module):\n",
    "    def __init__(self, args, backbone_net=None):\n",
    "        super(iVAE, self).__init__()\n",
    "        self.args = args\n",
    "        self.backbone_net = backbone_net\n",
    "        self.pool_layer = nn.Sequential(nn.AdaptiveAvgPool2d(output_size=(1,1)), nn.Flatten())\n",
    "\n",
    "        # latent space: [0:self.c_dim] [self.c_dim: self.sd_dim] [self.sd_dim:self.s_dim]\n",
    "        self.c_dim = args.c_dim\n",
    "        self.s_dim = args.s_dim\n",
    "        self.sd_dim = self.z_dim - self.s_dim - self.c_dim\n",
    "\n",
    "        dim = args.hidden_dim\n",
    "        self.encoder = nn.Sequential(nn.Linear(self.backbone_net.out_features, dim),\n",
    "                                     nn.BatchNorm1d(dim),\n",
    "                                     nn.ReLU(), nn.Dropout())\n",
    "        self.fc_mu = nn.Sequential(nn.Linear(dim, self.z_dim))\n",
    "        self.fc_logvar = nn.Sequential(nn.Linear(dim, self.z_dim))\n",
    "\n",
    "        self.decoder = nn.Sequential(nn.Linear(self.z_dim, dim),\n",
    "                                     nn.BatchNorm1d(dim),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(dim, self.backbone_net.out_features))\n",
    "\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "                        nn.Linear(self.s_dim, dim), nn.BatchNorm1d(dim), nn.ReLU(), nn.Dropout(),\n",
    "                        nn.Linear(dim, args.num_classes)\n",
    "            )\n",
    "        \n",
    "        self.domain_classifier = nn.Sequential(\n",
    "                        nn.Linear(self.sd_dim, dim), nn.BatchNorm1d(dim), nn.ReLU(), nn.Dropout(),\n",
    "                        nn.Linear(dim, args.num_domains)\n",
    "            )\n",
    "        self.domain_embedding = nn.Embedding(2, 256)\n",
    "        self.domain_mlp = MLP(256, domain_num_params)\n",
    "\n",
    "        print(self.encoder, self.fc_mu, self.fc_logvar)\n",
    "        print(self.decoder,self.classifier, self.domain_classifier)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def track_bn_stats(self, track):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm1d):\n",
    "                m.track_running_stats = track\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.track_running_stats = track\n",
    "\n",
    "    def extract_feature(self, x, u, track_bn=False):\n",
    "        self.track_bn_stats(track_bn)\n",
    "        x = self.backbone(x, track_bn)\n",
    "        h = self.encoder(x)\n",
    "        mu, log_var = self.fc_mu(h), self.fc_logvar(h)\n",
    "        if self.training:\n",
    "            z = self.reparameterize(mu, log_var)\n",
    "        else:\n",
    "            z = mu\n",
    "        tilde_z, _ = self.domain_influence(z, u) \n",
    "        return tilde_z\n",
    "\n",
    "    def encode(self, x, u, track_bn=False):\n",
    "\n",
    "        self.track_bn_stats(track_bn)\n",
    "\n",
    "        # sample z\n",
    "        h = self.encoder(x)\n",
    "        mu, log_var = self.fc_mu(h), self.fc_logvar(h)\n",
    "        if self.training:\n",
    "            z = self.reparameterize(mu, log_var)\n",
    "        else:\n",
    "            z = mu\n",
    "        \n",
    "        # de-influence u - \n",
    "        # remove the domain influcence; back to Gaussian- we are currently not using flow model\n",
    "        # for domain influence\n",
    "        #tilde_z, logdet_u = self.domain_influence(z, u)\n",
    "        \n",
    "        c_z, s_z, sd_z = z[:, :self.c_dim], z[:, self.c_dim:self.s_dim], z[:, -self.sd_dim:]\n",
    "        \n",
    "        #domain_embedding = self.domain_embedding(u)\n",
    "        #B, _ = domain_embedding.size()\n",
    "        # get logits\n",
    "        logits_class = self.predict(s_z, track_bn=track_bn)\n",
    "        \n",
    "        logits_domain = self.predict_domain(sd_z, track_bn=track_bn)\n",
    "        \n",
    "        return z, c_z, s_z, sd_z, mu, log_var, logits_class, logits_domain \n",
    "        # tilde_z is for domain adversarial, tilde_tilde_z is for KL p, z is for reconstruction and KL q. \n",
    "\n",
    " \n",
    "    def domain_influence(self, z, u):\n",
    "\n",
    "        if self.flow_type == 'nsf':\n",
    "            zcont = z[:, :-self.s_dim]\n",
    "            tilde_zs = self.domain_flow(z[:, -self.s_dim:], u)\n",
    "\n",
    "        else:\n",
    "            domain_embedding = self.domain_embedding(u)  # B,h_dim\n",
    "            B, _ = domain_embedding.size()\n",
    "            dsparams = self.domain_mlp(domain_embedding)  # B, ndim\n",
    "            dsparams = dsparams.view(B, self.s_dim, -1)\n",
    "            zcont = z[:,:self.c_dim]\n",
    "            tilde_zs, logdet = self.domain_flow(z[:,-self.s_dim:], dsparams)\n",
    "\n",
    "        tilde_z = torch.cat([zcont, tilde_zs], 1)\n",
    "\n",
    "        return tilde_z, logdet\n",
    "\n",
    "    def decode(self, z):\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x, u, track_bn=False):\n",
    "        self.track_bn_stats(track_bn)\n",
    "        x = self.backbone(x)\n",
    "        _, _, _, _, _, _, logit_c, logit_d = self.encode(x, u=u)\n",
    "        if self.training:\n",
    "            raise NotImplementedError\n",
    "            return tilde_z, logit\n",
    "        else:\n",
    "            return logit_c, logit_d\n",
    "\n",
    "    def backbone(self, x, track_bn=False):\n",
    "        self.track_bn_stats(track_bn)\n",
    "        out = self.backbone_net(x)\n",
    "        if len(out.size()) > 2:\n",
    "            out = self.pool_layer(out)\n",
    "        return out\n",
    "\n",
    "    def predict_class(self, z, track_bn=False):\n",
    "        self.track_bn_stats(track_bn)\n",
    "        return self.classifier(z)\n",
    "    \n",
    "    def predict_domain(self, z, track_bn=False):\n",
    "        self.track_bn_stats(track_bn)\n",
    "        return self.domain_classifier(z)\n",
    "\n",
    "    def get_parameters(self, base_lr=1.0):\n",
    "        \"\"\"A parameter list which decides optimization hyper-parameters,\n",
    "            such as the relative learning rate of each layer\n",
    "        \"\"\"\n",
    "        base_params = itertools.chain(self.encoder.parameters(), self.fc_mu.parameters(),\n",
    "                                      self.fc_logvar.parameters(), self.decoder.parameters(),\n",
    "                                      self.classifier.parameters(), \n",
    "                                      self.u_embedding.parameters(),\n",
    "                                      self.domain_flow.parameters(),\n",
    "                                      self.domain_mlp.parameters(),\n",
    "                                      )\n",
    "        params = [\n",
    "            {\"params\": self.backbone_net.parameters(), \"lr\": 0.1 * base_lr},\n",
    "            {\"params\": base_params, \"lr\": 1.0 * base_lr},\n",
    "        ]\n",
    "        return params\n",
    "\n",
    "\n",
    "\n",
    "delta = 1e-6\n",
    "softplus_ = nn.Softplus()\n",
    "softplus = lambda x: softplus_(x) + delta\n",
    "sigmoid_ = nn.Sigmoid()\n",
    "sigmoid = lambda x: sigmoid_(x) * (1 - delta) + 0.5 * delta\n",
    "sigmoid2 = lambda x: sigmoid(x) * 2.0\n",
    "logsigmoid = lambda x: -softplus(-x)\n",
    "log = lambda x: torch.log(x * 1e2) - np.log(1e2)\n",
    "logit = lambda x: log(x) - log(1 - x)\n",
    "\n",
    "\n",
    "def softmax(x, dim=-1):\n",
    "    e_x = torch.exp(x - x.max(dim=dim, keepdim=True)[0])\n",
    "    out = e_x / e_x.sum(dim=dim, keepdim=True)\n",
    "    return out\n",
    "\n",
    "def oper(array,oper,axis=-1,keepdims=False):\n",
    "    a_oper = oper(array)\n",
    "    if keepdims:\n",
    "        shape = []\n",
    "        for j,s in enumerate(array.size()):\n",
    "            shape.append(s)\n",
    "        shape[axis] = -1\n",
    "        a_oper = a_oper.view(*shape)\n",
    "    return a_oper\n",
    "\n",
    "def log_sum_exp(A, axis=-1, sum_op=torch.sum):    \n",
    "    maximum = lambda x: x.max(axis)[0]    \n",
    "    A_max = oper(A,maximum, axis, True)\n",
    "    summation = lambda x: sum_op(torch.exp(x-A_max), axis)\n",
    "    B = torch.log(oper(A,summation,axis,True)) + A_max    \n",
    "    return B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd0db0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args): \n",
    "    model = iVAE(args).to(device)\n",
    "    # define optimizer and lr scheduler\n",
    "    optimizer = SGD(classifier.get_parameters(),\n",
    "                    lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay, nesterov=True)\n",
    "    #optimizer = torch.optim.Adam(classifier.get_parameters(), lr=2e-4, weight_decay=args.weight_decay)\n",
    "\n",
    "    print(optimizer.param_groups[0]['lr'], ' *** lr')\n",
    "    lr_scheduler = LambdaLR(optimizer, lambda x:  args.lr * (1. + args.lr_gamma * float(x)) ** (-args.lr_decay))\n",
    "    print(optimizer.param_groups[0]['lr'], ' *** lr')\n",
    "    \n",
    "    if args.phase != 'train':\n",
    "        checkpoint = torch.load(logger.get_checkpoint_path('best'), map_location='cpu')\n",
    "        model.load_state_dict(checkpoint)\n",
    "    \n",
    "    best_acc1 = 0.\n",
    "    total_iter = 0\n",
    "    for epoch in range(args.epochs):\n",
    "        print(\"lr:\", lr_scheduler.get_last_lr(), optimizer.param_groups[0]['lr'])\n",
    "        # train for one epoch\n",
    "        train(train_source_iter, train_target_iter, model, optimizer,\n",
    "              lr_scheduler, epoch, args, total_iter)\n",
    "        total_iter += args.iters_per_epoch\n",
    "\n",
    "        torch.save(classifier.state_dict(), logger.get_checkpoint_path('latest'))\n",
    "        if acc1 > best_acc1:\n",
    "            shutil.copy(logger.get_checkpoint_path('latest'), logger.get_checkpoint_path('best'))\n",
    "        best_acc1 = max(acc1, best_acc1)\n",
    "    \n",
    "    print(\"best_acc1 = {:3.1f}\".format(best_acc1))\n",
    "    # evaluate on test set\n",
    "    classifier.load_state_dict(torch.load(logger.get_checkpoint_path('best')))\n",
    "    acc1 = utils.validate(test_loader, classifier, args, device)\n",
    "    print(\"test_acc1 = {:3.1f}\".format(acc1))\n",
    "    logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b8d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_source_iter: ForeverDataIterator, train_target_iter: ForeverDataIterator,\n",
    "          model,  optimizer: SGD,\n",
    "          lr_scheduler: LambdaLR, epoch: int, args: argparse.Namespace, total_iter):\n",
    "    batch_time = AverageMeter('Time', ':5.2f')\n",
    "    data_time = AverageMeter('Data', ':5.2f')\n",
    "    losses = AverageMeter('Loss', ':4.2f')\n",
    "    recon_losses = AverageMeter('Rec', ':4.2f')\n",
    "    vae_losses = AverageMeter('VAE', ':4.2f')\n",
    "    kl_style_losses = AverageMeter('KL_S', ':4.2f')\n",
    "    cauinf_losses = AverageMeter('CauInf', ':4.2f')\n",
    "    kl_content_losses = AverageMeter('KL_C', ':4.2f')\n",
    "    cls_losses = AverageMeter('Cls', ':4.2f')\n",
    "    ent_losses = AverageMeter('Ent', ':4.2f')\n",
    "    cls_accs = AverageMeter('Cls Acc', ':3.1f')\n",
    "    val_accs = AverageMeter('Val Acc', ':3.1f')\n",
    "    progress = ProgressMeter(\n",
    "        args.iters_per_epoch,\n",
    "        [batch_time, data_time, cls_losses, ent_losses, vae_losses, recon_losses, kl_style_losses, kl_content_losses, cauinf_losses, cls_accs, val_accs],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i in range(args.iters_per_epoch):\n",
    "        total_iter += 1\n",
    "        model.train()\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        x_s, labels_s, d_s = next(train_source_iter)\n",
    "        x_t, labels_t, d_t = next(train_target_iter)\n",
    "        x_s = x_s.to(device)\n",
    "        x_t = x_t.to(device)\n",
    "        labels_s = labels_s.to(device)\n",
    "        labels_t = labels_t.to(device)\n",
    "        x_all = torch.cat([x_s, x_t], 0)\n",
    "        d_all = torch.cat([d_s, d_t], 0).to(device)\n",
    "        label_all = torch.cat([labels_s, labels_t], 0)\n",
    "        losses_cls = []\n",
    "        losses_kl_style = []\n",
    "        losses_kl_content = []\n",
    "        img_all = []\n",
    "        tilde_z_all = []\n",
    "        y_t = None\n",
    "        y_s = []\n",
    "        labels_s = []\n",
    "        for id in range(args.n_domains):\n",
    "            domain_id = id\n",
    "            is_target = domain_id == args.n_domains-1\n",
    "            x_dom = x_all[d_all==id][:args.batch_size]\n",
    "            label_dom = label_all[d_all==id][:args.batch_size]\n",
    "            d_dom = d_all[d_all==id][:args.batch_size]\n",
    "            z, tilde_z, f, mu, log_var, zstyle, flow_zstyle, tilde_z_target, h1 = model.encode(x_dom, d_dom, track_bn=is_target)\n",
    "            logit = model.predict(f, track_bn=is_target)\n",
    "            # vae loss\n",
    "            cont_dim = args.z_dim - args.style_dim\n",
    "            kl_content = (-0.5 * (1 + log_var[:, :cont_dim] - mu[:, :cont_dim].pow(2) - log_var[:, :cont_dim].exp())).sum(\n",
    "                -1).mean()\n",
    "            C_max = torch.tensor(args.C_max_content)\n",
    "            C_content = torch.clamp(C_max / args.C_stop_iter * total_iter, 0, C_max.item())\n",
    "            loss_kl_content = 10 * (kl_content - C_content).abs()\n",
    "            if total_iter % 100 == 0:\n",
    "                print(kl_content.item(), C_content, total_iter, log_var[:,:cont_dim].mean(), mu[:,:cont_dim].mean())\n",
    "\n",
    "            kl_style = (-0.5 * (1 + log_var[:, cont_dim:] - mu[:, cont_dim:].pow(2) - log_var[:, cont_dim:].exp())).sum(\n",
    "                -1).mean()\n",
    "            C_max = torch.tensor(args.C_max_style)\n",
    "            C_style = torch.clamp(C_max / args.C_stop_iter * total_iter, 0, C_max.item())\n",
    "            loss_kl_style = args.beta * (kl_style - C_style).abs()\n",
    "\n",
    "            if not is_target:  # only source\n",
    "                losses_cls.append(F.cross_entropy(logit, label_dom))\n",
    "                y_s.append(logit)\n",
    "                labels_s.append(label_dom)\n",
    "            else:\n",
    "                y_t = logit\n",
    "            losses_kl_content.append(loss_kl_content)\n",
    "            losses_kl_style.append(loss_kl_style)\n",
    "            img_all.append(x_dom)\n",
    "            tilde_z_all.append(tilde_z)\n",
    "\n",
    "        img_all = torch.cat(img_all, 0)\n",
    "        tilde_z_all = torch.cat(tilde_z_all, 0)\n",
    "        img_all_hat = model.decode(tilde_z_all)\n",
    "\n",
    "        # vae loss\n",
    "        mean_loss_recon = F.mse_loss(img_all, img_all_hat, reduction='sum') / len(img_all)\n",
    "        mean_loss_kl_style = torch.stack(losses_kl_style, 0).mean()\n",
    "        mean_loss_kl_content = torch.stack(losses_kl_content, 0).mean()\n",
    "        mean_loss_vae = mean_loss_recon + mean_loss_kl_content + mean_loss_kl_style\n",
    "\n",
    "        # source classification\n",
    "        mean_loss_cls = torch.stack(losses_cls, 0).mean()\n",
    "\n",
    "        # sparse loss\n",
    "        loss_causal_influence = l1_loss(model.causal_influence)\n",
    "        cont_dim = args.z_dim - args.style_dim\n",
    "        loss_cls_content_influence = l1_loss(model.cls_influence[:, :cont_dim])\n",
    "        loss_cls_style_influence = l1_loss(model.cls_influence[:, cont_dim:])\n",
    "\n",
    "        # entropy loss\n",
    "        loss_ent = torch.tensor(0.)\n",
    "        if args.lambda_ent > 0:\n",
    "            output_t = y_t\n",
    "            entropy = F.cross_entropy(output_t, torch.softmax(output_t, dim=1), reduction='none').detach()\n",
    "            index = torch.nonzero((entropy < args.entropy_thr).float()).squeeze(-1)\n",
    "            select_output_t = output_t[index]\n",
    "            if len(select_output_t) > 0:\n",
    "                loss_ent = F.cross_entropy(select_output_t, torch.softmax(select_output_t, dim=1))\n",
    "\n",
    "\n",
    "        loss = mean_loss_cls + args.lambda_vae * mean_loss_vae + args.lambda_cauinf * loss_causal_influence + \\\n",
    "               + args.lambda_ent * loss_ent + \\\n",
    "               args.lambda_clscont * loss_cls_content_influence + args.lambda_clsstyle * loss_cls_style_influence\n",
    "\n",
    "        y_s = torch.cat(y_s, 0)\n",
    "        labels_s = torch.cat(labels_s, 0)\n",
    "        cls_acc = accuracy(y_s, labels_s)[0]\n",
    "        cls_losses.update(mean_loss_cls.item(), y_s.size(0))\n",
    "        recon_losses.update(mean_loss_recon.item(), x_all.size(0))\n",
    "        cls_accs.update(cls_acc.item(), y_s.size(0))\n",
    "        vae_losses.update(mean_loss_vae.item(), x_all.size(0))\n",
    "        ent_losses.update(loss_ent.item(), y_t.size(0))\n",
    "        kl_style_losses.update(mean_loss_kl_style.item(), x_all.size(0))\n",
    "        kl_content_losses.update(mean_loss_kl_content.item(), x_all.size(0))\n",
    "        cauinf_losses.update(loss_causal_influence.item(), 1)\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "\n",
    "            # not used in training\n",
    "            model.eval()\n",
    "            x_t = x_all[d_all==args.n_domains-1]\n",
    "            labels_t = label_all[d_all==args.n_domains-1]\n",
    "            with torch.no_grad():\n",
    "                y = model(x_t, d_all[d_all==args.n_domains-1])\n",
    "                cls_acc = accuracy(y, labels_t)[0]\n",
    "                val_accs.update(cls_acc.item(), x_t.size(0))\n",
    "            model.train()\n",
    "\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41732505",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SGD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kv/6wwnc8x97mz1rsrvgyqjjdjr0000gn/T/ipykernel_1602/3165023394.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m def train(train_source_iter: ForeverDataIterator, train_target_iter: ForeverDataIterator,\n\u001b[0;32m--> 145\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m           lr_scheduler: LambdaLR, epoch: int, args: argparse.Namespace, total_iter):\n\u001b[1;32m    147\u001b[0m     \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAverageMeter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':5.2f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SGD' is not defined"
     ]
    }
   ],
   "source": [
    "def _make_balanced_sampler(labels):\n",
    "    class_counts = np.bincount(labels)\n",
    "    class_weights = 1. / class_counts\n",
    "    weights = class_weights[labels]\n",
    "    return WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "def main(args: argparse.Namespace):\n",
    "    logger = CompleteLogger(args.log, args.phase)\n",
    "    print(args)\n",
    "    \n",
    "    cudnn.benchmark = True\n",
    "    dataset_list = []\n",
    "    domain_ids = []\n",
    "    all_domains = args.source+args.target\n",
    "    args.num_classes = 345\n",
    "    for source in args.source:\n",
    "        labels = torch.load(osp.join(args.root, 'domainnet_label_%s_train.pt' % source))\n",
    "        data = torch.load(osp.join(args.root, 'domainnet_%s_train.pt' % source))\n",
    "        ds = torch.cat([torch.tensor([all_domains.index(source)])] * len(data),0)\n",
    "        dataset = TensorDataset(data, labels, ds)\n",
    "        dataset_list.append(dataset)\n",
    "        domain_ids += ds\n",
    "    train_source_dataset = torch.utils.data.ConcatDataset(dataset_list)\n",
    "    train_source_dataset.domain_ids = domain_ids\n",
    "    labels = torch.load(osp.join(args.root, 'domainnet_label_%s_train.pt' % args.target[0]))\n",
    "    data = torch.load(osp.join(args.root, 'domainnet_%s_train.pt' % args.target[0]))\n",
    "    dt = torch.cat([torch.tensor([all_domains.index(args.target[0])])] * len(data),0)\n",
    "    train_target_dataset = TensorDataset(data, labels, dt)\n",
    "    train_source_loader = DataLoader(train_source_dataset, batch_size=(args.n_domains-1)*args.batch_size,\n",
    "                                     num_workers=args.workers, drop_last=True,\n",
    "                                     sampler=_make_balanced_sampler(train_source_dataset.domain_ids))\n",
    "    train_target_loader = DataLoader(train_target_dataset, batch_size=args.batch_size,\n",
    "                                     shuffle=True, num_workers=args.workers, drop_last=True,\n",
    "                                     )\n",
    "    train_source_iter = ForeverDataIterator(train_source_loader)\n",
    "    train_target_iter = ForeverDataIterator(train_target_loader)\n",
    "\n",
    "\n",
    "    labels = torch.load(osp.join(args.root, 'domainnet_label_%s_val.pt' % args.target[0]))\n",
    "    data = torch.load(osp.join(args.root, 'domainnet_%s_val.pt' % args.target[0]))\n",
    "    val_dataset = TensorDataset(data, labels)\n",
    "\n",
    "    labels = torch.load(osp.join(args.root, 'domainnet_label_%s_test.pt' % args.target[0]))\n",
    "    data = torch.load(osp.join(args.root, 'domainnet_%s_test.pt' % args.target[0]))\n",
    "    test_dataset = TensorDataset(data, labels)\n",
    "\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)\n",
    "\n",
    "\n",
    "\n",
    "    # create model\n",
    "    print(\"=> using model '{}'\".format(args.arch))\n",
    "    classifier = iVAE(args).to(device)\n",
    "\n",
    "    # define optimizer and lr scheduler\n",
    "    optimizer = SGD(classifier.get_parameters(),\n",
    "                    lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay, nesterov=True)\n",
    "    #optimizer = torch.optim.Adam(classifier.get_parameters(), lr=2e-4, weight_decay=args.weight_decay)\n",
    "    print(optimizer.param_groups[0]['lr'], ' *** lr')\n",
    "    lr_scheduler = LambdaLR(optimizer, lambda x:  args.lr * (1. + args.lr_gamma * float(x)) ** (-args.lr_decay))\n",
    "    print(optimizer.param_groups[0]['lr'], ' *** lr')\n",
    "\n",
    "    # resume from the best checkpoint\n",
    "    if args.phase != 'train':\n",
    "        checkpoint = torch.load(logger.get_checkpoint_path('best'), map_location='cpu')\n",
    "        classifier.load_state_dict(checkpoint)\n",
    "\n",
    "    # analysis the model\n",
    "    if args.phase == 'analysis':\n",
    "        # extract features from both domains\n",
    "        feature_extractor = nn.Sequential(classifier.backbone, classifier.pool_layer, classifier.bottleneck).to(device)\n",
    "        source_feature = collect_feature(train_source_loader, feature_extractor, device)\n",
    "        target_feature = collect_feature(train_target_loader, feature_extractor, device)\n",
    "        # plot t-SNE\n",
    "        tSNE_filename = osp.join(logger.visualize_directory, 'TSNE.pdf')\n",
    "        tsne.visualize(source_feature, target_feature, tSNE_filename)\n",
    "        print(\"Saving t-SNE to\", tSNE_filename)\n",
    "        # calculate A-distance, which is a measure for distribution discrepancy\n",
    "        A_distance = a_distance.calculate(source_feature, target_feature, device)\n",
    "        print(\"A-distance =\", A_distance)\n",
    "        return\n",
    "\n",
    "    if args.phase == 'test':\n",
    "        acc1 = utils.validate(test_loader, classifier, args, device)\n",
    "        print(acc1)\n",
    "        return\n",
    "\n",
    "    # start training\n",
    "    best_acc1 = 0.\n",
    "    total_iter = 0\n",
    "    for epoch in range(args.epochs):\n",
    "        print(\"lr:\", lr_scheduler.get_last_lr(), optimizer.param_groups[0]['lr'])\n",
    "        # train for one epoch\n",
    "        train(train_source_iter, train_target_iter, classifier, optimizer,\n",
    "              lr_scheduler, epoch, args, total_iter)\n",
    "        total_iter += args.iters_per_epoch\n",
    "        # evaluate on validation set\n",
    "        acc1 = utils.validate(train_source_loader, classifier, args, device)\n",
    "        print(' * Src Acc@1 %.3f' % (acc1))\n",
    "        acc1 = utils.validate(val_loader, classifier, args, device)\n",
    "        print(' * Val Acc@1 %.3f' % (acc1))\n",
    "        acc1 = utils.validate(test_loader, classifier, args, device)\n",
    "        print(' * Test Acc@1 %.3f' % (acc1))\n",
    "\n",
    "        source_feature = collect_feature(train_source_loader, classifier.extract_feature, device)\n",
    "        target_feature = collect_feature(train_target_loader, classifier.extract_feature, device)\n",
    "        # plot t-SNE\n",
    "        tSNE_filename = osp.join(logger.visualize_directory, 'TSNE.pdf')\n",
    "        tsne.visualize(source_feature, target_feature, tSNE_filename)\n",
    "        print(\"Saving t-SNE to\", tSNE_filename)\n",
    "\n",
    "        # remember best acc@1 and save checkpoint\n",
    "        torch.save(classifier.state_dict(), logger.get_checkpoint_path('latest'))\n",
    "        if acc1 > best_acc1:\n",
    "            shutil.copy(logger.get_checkpoint_path('latest'), logger.get_checkpoint_path('best'))\n",
    "        best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "    print(\"best_acc1 = {:3.1f}\".format(best_acc1))\n",
    "\n",
    "    # evaluate on test set\n",
    "    classifier.load_state_dict(torch.load(logger.get_checkpoint_path('best')))\n",
    "    acc1 = utils.validate(test_loader, classifier, args, device)\n",
    "    print(\"test_acc1 = {:3.1f}\".format(acc1))\n",
    "\n",
    "    logger.close()\n",
    "\n",
    "def l1_loss(x):\n",
    "    return torch.mean(torch.abs(x))\n",
    "\n",
    "\n",
    "\n",
    "def train(train_source_iter: ForeverDataIterator, train_target_iter: ForeverDataIterator,\n",
    "          model,  optimizer: SGD,\n",
    "          lr_scheduler: LambdaLR, epoch: int, args: argparse.Namespace, total_iter):\n",
    "    batch_time = AverageMeter('Time', ':5.2f')\n",
    "    data_time = AverageMeter('Data', ':5.2f')\n",
    "    losses = AverageMeter('Loss', ':4.2f')\n",
    "    recon_losses = AverageMeter('Rec', ':4.2f')\n",
    "    vae_losses = AverageMeter('VAE', ':4.2f')\n",
    "    kl_style_losses = AverageMeter('KL_S', ':4.2f')\n",
    "    cauinf_losses = AverageMeter('CauInf', ':4.2f')\n",
    "    kl_content_losses = AverageMeter('KL_C', ':4.2f')\n",
    "    cls_losses = AverageMeter('Cls', ':4.2f')\n",
    "    ent_losses = AverageMeter('Ent', ':4.2f')\n",
    "    cls_accs = AverageMeter('Cls Acc', ':3.1f')\n",
    "    val_accs = AverageMeter('Val Acc', ':3.1f')\n",
    "    progress = ProgressMeter(\n",
    "        args.iters_per_epoch,\n",
    "        [batch_time, data_time, cls_losses, ent_losses, vae_losses, recon_losses, kl_style_losses, kl_content_losses, cauinf_losses, cls_accs, val_accs],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i in range(args.iters_per_epoch):\n",
    "        total_iter += 1\n",
    "        model.train()\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        x_s, labels_s, d_s = next(train_source_iter)\n",
    "        x_t, labels_t, d_t = next(train_target_iter)\n",
    "        x_s = x_s.to(device)\n",
    "        x_t = x_t.to(device)\n",
    "        labels_s = labels_s.to(device)\n",
    "        labels_t = labels_t.to(device)\n",
    "        x_all = torch.cat([x_s, x_t], 0)\n",
    "        d_all = torch.cat([d_s, d_t], 0).to(device)\n",
    "        label_all = torch.cat([labels_s, labels_t], 0)\n",
    "        losses_cls = []\n",
    "        losses_kl_style = []\n",
    "        losses_kl_content = []\n",
    "        img_all = []\n",
    "        tilde_z_all = []\n",
    "        y_t = None\n",
    "        y_s = []\n",
    "        labels_s = []\n",
    "        for id in range(args.n_domains):\n",
    "            domain_id = id\n",
    "            is_target = domain_id == args.n_domains-1\n",
    "            x_dom = x_all[d_all==id][:args.batch_size]\n",
    "            label_dom = label_all[d_all==id][:args.batch_size]\n",
    "            d_dom = d_all[d_all==id][:args.batch_size]\n",
    "            z, tilde_z, f, mu, log_var, zstyle, flow_zstyle, tilde_z_target, h1 = model.encode(x_dom, d_dom, track_bn=is_target)\n",
    "            logit = model.predict(f, track_bn=is_target)\n",
    "            # vae loss\n",
    "            cont_dim = args.z_dim - args.style_dim\n",
    "            kl_content = (-0.5 * (1 + log_var[:, :cont_dim] - mu[:, :cont_dim].pow(2) - log_var[:, :cont_dim].exp())).sum(\n",
    "                -1).mean()\n",
    "            C_max = torch.tensor(args.C_max_content)\n",
    "            C_content = torch.clamp(C_max / args.C_stop_iter * total_iter, 0, C_max.item())\n",
    "            loss_kl_content = 10 * (kl_content - C_content).abs()\n",
    "            if total_iter % 100 == 0:\n",
    "                print(kl_content.item(), C_content, total_iter, log_var[:,:cont_dim].mean(), mu[:,:cont_dim].mean())\n",
    "\n",
    "            kl_style = (-0.5 * (1 + log_var[:, cont_dim:] - mu[:, cont_dim:].pow(2) - log_var[:, cont_dim:].exp())).sum(\n",
    "                -1).mean()\n",
    "            C_max = torch.tensor(args.C_max_style)\n",
    "            C_style = torch.clamp(C_max / args.C_stop_iter * total_iter, 0, C_max.item())\n",
    "            loss_kl_style = args.beta * (kl_style - C_style).abs()\n",
    "\n",
    "            if not is_target:  # only source\n",
    "                losses_cls.append(F.cross_entropy(logit, label_dom))\n",
    "                y_s.append(logit)\n",
    "                labels_s.append(label_dom)\n",
    "            else:\n",
    "                y_t = logit\n",
    "            losses_kl_content.append(loss_kl_content)\n",
    "            losses_kl_style.append(loss_kl_style)\n",
    "            img_all.append(x_dom)\n",
    "            tilde_z_all.append(tilde_z)\n",
    "\n",
    "        img_all = torch.cat(img_all, 0)\n",
    "        tilde_z_all = torch.cat(tilde_z_all, 0)\n",
    "        img_all_hat = model.decode(tilde_z_all)\n",
    "\n",
    "        # vae loss\n",
    "        mean_loss_recon = F.mse_loss(img_all, img_all_hat, reduction='sum') / len(img_all)\n",
    "        mean_loss_kl_style = torch.stack(losses_kl_style, 0).mean()\n",
    "        mean_loss_kl_content = torch.stack(losses_kl_content, 0).mean()\n",
    "        mean_loss_vae = mean_loss_recon + mean_loss_kl_content + mean_loss_kl_style\n",
    "\n",
    "        # source classification\n",
    "        mean_loss_cls = torch.stack(losses_cls, 0).mean()\n",
    "\n",
    "        # sparse loss\n",
    "        loss_causal_influence = l1_loss(model.causal_influence)\n",
    "        cont_dim = args.z_dim - args.style_dim\n",
    "        loss_cls_content_influence = l1_loss(model.cls_influence[:, :cont_dim])\n",
    "        loss_cls_style_influence = l1_loss(model.cls_influence[:, cont_dim:])\n",
    "\n",
    "        # entropy loss\n",
    "        loss_ent = torch.tensor(0.)\n",
    "        if args.lambda_ent > 0:\n",
    "            output_t = y_t\n",
    "            entropy = F.cross_entropy(output_t, torch.softmax(output_t, dim=1), reduction='none').detach()\n",
    "            index = torch.nonzero((entropy < args.entropy_thr).float()).squeeze(-1)\n",
    "            select_output_t = output_t[index]\n",
    "            if len(select_output_t) > 0:\n",
    "                loss_ent = F.cross_entropy(select_output_t, torch.softmax(select_output_t, dim=1))\n",
    "\n",
    "\n",
    "        loss = mean_loss_cls + args.lambda_vae * mean_loss_vae + args.lambda_cauinf * loss_causal_influence + \\\n",
    "               + args.lambda_ent * loss_ent + \\\n",
    "               args.lambda_clscont * loss_cls_content_influence + args.lambda_clsstyle * loss_cls_style_influence\n",
    "\n",
    "        y_s = torch.cat(y_s, 0)\n",
    "        labels_s = torch.cat(labels_s, 0)\n",
    "        cls_acc = accuracy(y_s, labels_s)[0]\n",
    "        cls_losses.update(mean_loss_cls.item(), y_s.size(0))\n",
    "        recon_losses.update(mean_loss_recon.item(), x_all.size(0))\n",
    "        cls_accs.update(cls_acc.item(), y_s.size(0))\n",
    "        vae_losses.update(mean_loss_vae.item(), x_all.size(0))\n",
    "        ent_losses.update(loss_ent.item(), y_t.size(0))\n",
    "        kl_style_losses.update(mean_loss_kl_style.item(), x_all.size(0))\n",
    "        kl_content_losses.update(mean_loss_kl_content.item(), x_all.size(0))\n",
    "        cauinf_losses.update(loss_causal_influence.item(), 1)\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "\n",
    "            # not used in training\n",
    "            model.eval()\n",
    "            x_t = x_all[d_all==args.n_domains-1]\n",
    "            labels_t = label_all[d_all==args.n_domains-1]\n",
    "            with torch.no_grad():\n",
    "                y = model(x_t, d_all[d_all==args.n_domains-1])\n",
    "                cls_acc = accuracy(y, labels_t)[0]\n",
    "                val_accs.update(cls_acc.item(), x_t.size(0))\n",
    "            model.train()\n",
    "\n",
    "            progress.display(i)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='DANN for Unsupervised Domain Adaptation')\n",
    "    # dataset parameters\n",
    "    parser.add_argument('--root', type=str, default='../da_datasets/domainnet',\n",
    "                        help='root path of dataset')\n",
    "    parser.add_argument('-d', '--data', metavar='DATA', default='DomainNet', choices=utils.get_dataset_names(),\n",
    "                        help='dataset: ' + ' | '.join(utils.get_dataset_names()) +\n",
    "                             ' (default: Office31)')\n",
    "    parser.add_argument('-s', '--source', help='source domain(s)', default='i,p,q,r,s')\n",
    "    parser.add_argument('-t', '--target', help='target domain(s)', default='c')\n",
    "    parser.add_argument('--train-resizing', type=str, default='default')\n",
    "    parser.add_argument('--val-resizing', type=str, default='default')\n",
    "    parser.add_argument('--resize-size', type=int, default=224,\n",
    "                        help='the image size after resizing')\n",
    "    parser.add_argument('--no-hflip', action='store_true',\n",
    "                        help='no random horizontal flipping during training')\n",
    "    parser.add_argument('--norm-mean', type=float, nargs='+',\n",
    "                        default=(0.485, 0.456, 0.406), help='normalization mean')\n",
    "    parser.add_argument('--norm-std', type=float, nargs='+',\n",
    "                        default=(0.229, 0.224, 0.225), help='normalization std')\n",
    "    # model parameters\n",
    "    parser.add_argument('-a', '--arch', metavar='ARCH', default='resnet101',\n",
    "                        choices=utils.get_model_names(),\n",
    "                        help='backbone architecture: ' +\n",
    "                             ' | '.join(utils.get_model_names()) +\n",
    "                             ' (default: resnet18)')\n",
    "    parser.add_argument('--bottleneck-dim', default=2048, type=int,\n",
    "                        help='Dimension of bottleneck')\n",
    "    parser.add_argument('--no-pool', action='store_true',\n",
    "                        help='no pool layer after the feature extractor.')\n",
    "    parser.add_argument('--scratch', action='store_true', help='whether train from scratch.')\n",
    "    parser.add_argument('--trade-off', default=1., type=float,\n",
    "                        help='the trade-off hyper-parameter for transfer loss')\n",
    "    # training parameters\n",
    "    parser.add_argument('-b', '--batch-size', default=128, type=int,\n",
    "                        metavar='N',\n",
    "                        help='mini-batch size (default: 32)')\n",
    "    parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,\n",
    "                        metavar='LR', help='initial learning rate', dest='lr')\n",
    "    parser.add_argument('--lr-gamma', default=0.0003, type=float, help='parameter for lr scheduler')\n",
    "    parser.add_argument('--lr-decay', default=0.75, type=float, help='parameter for lr scheduler')\n",
    "    parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                        help='momentum')\n",
    "    parser.add_argument('--wd', '--weight-decay',default=5e-4, type=float,\n",
    "                        metavar='W', help='weight decay (default: 1e-3)',\n",
    "                        dest='weight_decay')\n",
    "    parser.add_argument('-j', '--workers', default=2, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 2)')\n",
    "    parser.add_argument('--epochs', default=40, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    parser.add_argument('-i', '--iters-per-epoch', default=2500, type=int,\n",
    "                        help='Number of iterations per epoch')\n",
    "    parser.add_argument('-p', '--print-freq', default=100, type=int,\n",
    "                        metavar='N', help='print frequency (default: 100)')\n",
    "    parser.add_argument('-e', '--eval-freq', default=100, type=int,\n",
    "                        metavar='N', help='print frequency (default: 100)')\n",
    "    parser.add_argument('--seed', default=None, type=int,\n",
    "                        help='seed for initializing training. ')\n",
    "    parser.add_argument('--per-class-eval', action='store_true',\n",
    "                        help='whether output per-class accuracy during evaluation')\n",
    "    parser.add_argument(\"--log\", type=str, default='logs',\n",
    "                        help=\"Where to save logs, checkpoints and debugging images.\")\n",
    "    parser.add_argument(\"--phase\", type=str, default='train', choices=['train', 'test', 'analysis'],\n",
    "                        help=\"When phase is 'test', only test the model.\"\n",
    "                             \"When phase is 'analysis', only analysis the model.\")\n",
    "    parser.add_argument('--z_dim', type=int, default=512, metavar='N')\n",
    "    parser.add_argument('--style_dim', type=int, default=64, metavar='N')\n",
    "    parser.add_argument('--beta', type=float, default=10., metavar='N')\n",
    "    parser.add_argument('--name', type=str, default='experiments', metavar='N')\n",
    "    parser.add_argument('--mode', type=str, default='vae', metavar='N')\n",
    "    parser.add_argument('--cls_mode', type=str, default='style', metavar='N')\n",
    "    parser.add_argument('--flow', type=str, default='ddsf', metavar='N')\n",
    "    parser.add_argument('--flow_dim', type=int, default=16, metavar='N')\n",
    "    parser.add_argument('--flow_nlayer', type=int, default=2, metavar='N')\n",
    "    parser.add_argument('--norm_id', type=int, default=5, metavar='N')\n",
    "    parser.add_argument('--init_value', type=float, default=0.0, metavar='N')\n",
    "    parser.add_argument('--flow_bound', type=int, default=5, metavar='N')\n",
    "    parser.add_argument('--flow_bins', type=int, default=8, metavar='N')\n",
    "    parser.add_argument('--flow_order', type=str, default='linear', metavar='N')\n",
    "    parser.add_argument('--net', type=str, default='dirt', metavar='N')\n",
    "    parser.add_argument('--n_flow', type=int, default=2, metavar='N')\n",
    "    parser.add_argument('--cls_dim', type=int, default=1024, metavar='N')\n",
    "    parser.add_argument('--cls_nlayer', type=int, default=2, metavar='N')\n",
    "    parser.add_argument('--lambda_vae', type=float, default=0.001, metavar='N')\n",
    "    parser.add_argument('--lambda_cls', type=float, default=1., metavar='N')\n",
    "    parser.add_argument('--lambda_cauinf', type=float, default=0.1, metavar='N')\n",
    "    parser.add_argument('--lambda_clscont', type=float, default=.0, metavar='N')\n",
    "    parser.add_argument('--lambda_clsstyle', type=float, default=.0, metavar='N')\n",
    "    parser.add_argument('--lambda_ent', type=float, default=.1, metavar='N')\n",
    "    parser.add_argument('--lambda_vat_s', type=float, default=0, metavar='N')\n",
    "    parser.add_argument('--lambda_vat_t', type=float, default=0, metavar='N')\n",
    "    parser.add_argument('--entropy_thr', type=float, default=0.5, metavar='N')\n",
    "    parser.add_argument('--C_max', type=float, default=15, metavar='N')\n",
    "    parser.add_argument('--C_max_content', type=float, default=120., metavar='N')\n",
    "    parser.add_argument('--C_max_style', type=float, default=20., metavar='N')\n",
    "    parser.add_argument('--max_iter', type=int, default=50000, metavar='N')\n",
    "    parser.add_argument('--C_stop_iter', type=int, default=10000, metavar='N')\n",
    "    parser.add_argument('--max_epoch', type=int, default=1000, metavar='N')\n",
    "    args = parser.parse_args()\n",
    "    model_id = '%s-%s-%s-%s-lam%s-beta_%s-D%d' % (args.data, args.target[0], args.name, args.mode, args.lambda_vae, args.beta,\n",
    "                                                         args.style_dim)\n",
    "    args.log = os.path.join(args.log, model_id)\n",
    "\n",
    "    args.source = [i for i in args.source.split(',')]\n",
    "    args.ta rget = [i for i in args.target.split(',')]\n",
    "    args.n_domains = len(args.source) + len(args.target)\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f418fd57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1fd00be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "442fc360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f9a1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5703b07d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
